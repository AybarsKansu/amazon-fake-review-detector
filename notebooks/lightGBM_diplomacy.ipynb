{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5b042ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e9f08e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(base_path, \"data\", \"processed\", \"diplomacy\")\n",
    "\n",
    "categorical_features = [\"speaker\", \"receiver\", \"season\"]\n",
    "col_types = {col: 'object' for col in categorical_features}\n",
    "\n",
    "data = pd.read_parquet(os.path.join(data_path, \"diplomacy_processed.parquet\"))\n",
    "data = data.astype(col_types)\n",
    "train_df = pd.read_parquet(os.path.join(data_path, \"train_processed.parquet\"))\n",
    "train_df = train_df.astype(col_types)\n",
    "val_df = pd.read_parquet(os.path.join(data_path, \"val_processed.parquet\"))\n",
    "val_df = val_df.astype(col_types)\n",
    "test_df = pd.read_parquet(os.path.join(data_path, \"test_processed.parquet\"))\n",
    "test_df = test_df.astype(col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6e9e56ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id', 'speaker', 'receiver', 'message_text', 'sender_intention',\n",
      "       'game_score', 'game_score_delta', 'year', 'season', 'original_fold',\n",
      "       'target', 'cleaned_text', 'message_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d0bedf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('target', axis=1)\n",
    "y_train = train_df['target']\n",
    "X_val = val_df.drop('target', axis=1)\n",
    "y_val = val_df['target']\n",
    "X_test = test_df.drop('target', axis=1)\n",
    "y_test = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1085aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 13132\n"
     ]
    }
   ],
   "source": [
    "print(f\"train set size: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2b6ba425",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"game_score\", \"game_score_delta\", \"year\", \"message_length\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "  (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "  (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = [\"speaker\", \"receiver\", \"season\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "  (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"most_frequent\")),\n",
    "  (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "text_feature = \"cleaned_text\"\n",
    "text_transformer = TfidfVectorizer()\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "  ('text', text_transformer, text_feature),\n",
    "  ('num', numeric_transformer, numeric_features),\n",
    "  ('cat', categorical_transformer, categorical_features)\n",
    "], remainder=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a1b30527",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = pd.concat([X_train, X_val])\n",
    "y_train_val = pd.concat([y_train, y_val])\n",
    "# because gridsearch expects the formal as x and y, we concat train and validation set; but modify how gridsearch splits data\n",
    "split_index = [-1] * len(X_train) + [0] * len(X_val)\n",
    "ps = PredefinedSplit(test_fold=split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d7b77365",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lgbm_smote = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('sampler', SMOTE(random_state=42)),\n",
    "    ('model', lgb.LGBMClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "88614ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = {\n",
    "    'preprocessor__text__max_features': [5000],\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__learning_rate': [0.1, 0.5, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b62e513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipeline_lgbm_smote, \n",
    "    param_grid_lgbm, \n",
    "    cv=ps,\n",
    "    scoring='f1_weighted', \n",
    "    n_jobs=4, \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ee505aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 13901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 113245\n",
      "[LightGBM] [Info] Number of data points in the train set: 27802, number of used features: 1821\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 13901, number of negative: 13901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 113245\n",
      "[LightGBM] [Info] Number of data points in the train set: 27802, number of used features: 1821\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Truth       0.91      0.99      0.95      2501\n",
      "   Deception       0.24      0.02      0.04       240\n",
      "\n",
      "    accuracy                           0.91      2741\n",
      "   macro avg       0.58      0.51      0.50      2741\n",
      "weighted avg       0.85      0.91      0.87      2741\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Truth       0.91      0.99      0.95      2501\n",
      "   Deception       0.24      0.02      0.04       240\n",
      "\n",
      "    accuracy                           0.91      2741\n",
      "   macro avg       0.58      0.51      0.50      2741\n",
      "weighted avg       0.85      0.91      0.87      2741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aybars\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_val, y_train_val)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Truth', 'Deception']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lgbm_weighted = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', lgb.LGBMClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced' \n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e19df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = {\n",
    "    'preprocessor__text__max_features': [5000],\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__learning_rate': [0.1, 0.5, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03640dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipeline_lgbm_weighted, \n",
    "    param_grid_lgbm, \n",
    "    cv=ps, \n",
    "    scoring='f1_macro',\n",
    "    n_jobs=4, \n",
    "    verbose=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
