{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e53e613",
   "metadata": {},
   "source": [
    "Just for the sake of checking the model and the data, I will first just implement naive bayes model for toys and games category. And also this provides me an insight about hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b0ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2525ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(base_path, \"data\", \"processed\", \"Toys_and_Games\")\n",
    "DATA_PATH = os.path.join(data_dir, \"toys_and_games.parquet\")\n",
    "\n",
    "data = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(), 'cleaned_text'),\n",
    "        ('numeric', numeric_transformer, ['overall', 'helpfulness_ratio']) \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"sampler\", RandomUnderSampler(random_state=42)), (\"model\", MultinomialNB())])\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__text__max_features': [7500, 15000],  # En sık geçen kaç kelime alınsın?\n",
    "    'preprocessor__text__ngram_range': [(1, 1), (1, 2)], # Tekli kelimeler mi, ikili gruplar da mı?\n",
    "    'model__alpha': [0.1, 0.5, 1.0]                     # Naive Bayes'in düzgünleştirme parametresi\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=4, verbose=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac811b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOptimization completed\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Best F1 Score: {grid_search.best_score_:.4f}\")\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# En iyi modeli al\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# En iyi model ile Test seti üzerinde tahmin yap\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Sınıflandırma Raporu\n",
    "print(\"final test set report\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Real (0)', 'Spam (1)']))\n",
    "\n",
    "# Karmaşıklık Matrisi (Confusion Matrix)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Real (0)', 'Spam (1)'],\n",
    "            yticklabels=['Real (0)', 'Spam (1)'])\n",
    "plt.ylabel('Real Value')\n",
    "plt.xlabel('Estimation')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc454cf",
   "metadata": {},
   "source": [
    "Best F1 Score: 0.9160\n",
    "Best Hyperparameters:\n",
    "{'model__alpha': 1.0, 'preprocessor__text__max_features': 15000, 'preprocessor__text__ngram_range': (1, 2)}\n",
    "----------------------------------------\n",
    "FİNAL TEST SETİ PERFORMANS RAPORU\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "Gerçek Yorum (0)       0.68      0.88      0.77     66877\n",
    "  Spam Yorum (1)       0.97      0.92      0.95    332551\n",
    "\n",
    "        accuracy                           0.91    399428\n",
    "       macro avg       0.83      0.90      0.86    399428\n",
    "    weighted avg       0.93      0.91      0.92    399428\n",
    "\n",
    "The model achieved an overall accuracy of 91% and a cross-validated F1 score of 0.916, which indicates strong generalization performance.\n",
    "\n",
    "The model performs very well on detecting spam reviews, with a precision of 0.97 and recall of 0.92.\n",
    "\n",
    "The performance on genuine reviews is weaker in comparison, with precision = 0.68 and recall = 0.88.\n",
    "\n",
    "Overall, the model is biased toward the majority class (spam), which is expected given the strong class imbalance in the dataset. The imbalance likely causes the model to favor predicting spam more confidently while misclassifying some real reviews.\n",
    "\n",
    "To improve performance on the minority class (real comments), I will apply oversampling with SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e70863",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\n",
    "  \"Cell_Phones_and_Accessories\", \n",
    "  \"Clothing_Shoes_and_Jewelry\", \n",
    "  \"Electronics\", \n",
    "  \"Home_and_Kitchen\", \n",
    "  \"Sports_and_Outdoors\",\n",
    "  \"Toys_and_Games\"]\n",
    "\n",
    "TEST_SIZE = 0.20\n",
    "RANDOM_STATE = 42\n",
    "CV_FOLDS = 3\n",
    "N_JOBS = 4 # cpu's to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf052824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cell_Phones_and_Accessories\n",
      "'Cell_Phones_and_Accessories' model has already created.\n",
      "Processing Clothing_Shoes_and_Jewelry\n",
      "'Clothing_Shoes_and_Jewelry' model has already created.\n",
      "Processing Electronics\n",
      "original size 7574169\n",
      "Grid Search starts for category Electronics\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best model found for category Electronics\n",
      "Results saved\n",
      "Model for Electronics saved to c:\\work environment\\Projects\\amazon-spam-review\\models\\Electronics\\naive_bayes_electronics.joblib\n",
      "Processing Home_and_Kitchen\n",
      "'Home_and_Kitchen' model has already created.\n",
      "Processing Sports_and_Outdoors\n",
      "'Sports_and_Outdoors' model has already created.\n",
      "Processing Toys_and_Games\n",
      "'Toys_and_Games' model has already created.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "results_file = os.path.join(os.path.dirname(os.getcwd()), \"reports\", \"model_result.csv\")\n",
    "param_grid = {\n",
    "  'preprocessor__text__max_features': [15000],\n",
    "  'preprocessor__text__ngram_range': [(1, 2)],\n",
    "  'model__alpha': [1.0, 1.5]\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "  print(f\"Processing {category}\")\n",
    "\n",
    "  model_dir = os.path.join(base_path, \"models\", category)\n",
    "  model_filename = f\"naive_bayes_{category.lower()}.joblib\"\n",
    "  model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "  if os.path.exists(model_path):\n",
    "    print(f\"'{category}' model has already created.\")\n",
    "    continue\n",
    "  \n",
    "  start_time = time.time()\n",
    "\n",
    "  base_path = os.path.dirname(os.getcwd())\n",
    "  data_dir = os.path.join(base_path, \"data\", \"processed\", category)\n",
    "  data_path = os.path.join(data_dir, f\"{category.lower()}.parquet\")\n",
    "\n",
    "  if not os.path.exists(data_path):\n",
    "    print(f\"No data found for category {category} at {data_path}\")\n",
    "    print(\"Skipping\")\n",
    "    continue\n",
    "\n",
    "  data = pd.read_parquet(data_path)\n",
    "\n",
    "  if category == \"Electronics\":\n",
    "    if len(data) > 1000000:\n",
    "      print(f\"original size {len(data)}\")\n",
    "      data = data.sample(n = 3787084, random_state=RANDOM_STATE)\n",
    "\n",
    "  X = data.drop(\"class\", axis=1)\n",
    "  y = data[\"class\"]\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "  \n",
    "  numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=0))])\n",
    "  \n",
    "  preprocessor = ColumnTransformer(transformers=[\n",
    "    ('text', TfidfVectorizer(), 'cleaned_text'),\n",
    "    ('numeric', numeric_transformer, ['overall', 'helpfulness_ratio'])\n",
    "  ])\n",
    "  \n",
    "  pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('sampler', RandomUnderSampler(random_state=RANDOM_STATE)),\n",
    "    ('model', MultinomialNB())\n",
    "  ])\n",
    "  \n",
    "  grid_search = GridSearchCV(pipeline, param_grid, cv=CV_FOLDS, scoring='f1_weighted', n_jobs=N_JOBS, verbose=1)\n",
    "  \n",
    "  print(f\"Grid Search starts for category {category}\")\n",
    "  grid_search.fit(X_train, y_train)\n",
    "  \n",
    "  print(f\"Best model found for category {category}\")\n",
    "  best_model = grid_search.best_estimator_\n",
    "  y_pred = best_model.predict(X_test)\n",
    "  \n",
    "  report = classification_report(y_test, y_pred, output_dict=True)\n",
    "  \n",
    "  result_data = {\n",
    "    'category': category,\n",
    "    'best_cv_f1_score': grid_search.best_score_,\n",
    "    'test_accuracy': report['accuracy'],\n",
    "    'test_f1_real_review': report['0']['f1-score'],\n",
    "    'test_precision_real_review': report['0']['precision'],\n",
    "    'test_recall_real_review': report['0']['recall'],\n",
    "    'test_f1_spam_review': report['1']['f1-score'],\n",
    "    'test_precision_spam_review': report['1']['precision'],\n",
    "    'test_recall_spam_review': report['1']['recall'],\n",
    "    'best_params': str(grid_search.best_params_),\n",
    "    'training_time_minutes': (time.time() - start_time) / 60\n",
    "  }\n",
    "  all_results.append(result_data)\n",
    "  \n",
    "  temp_df = pd.DataFrame([result_data])\n",
    "  header = not os.path.exists(results_file)\n",
    "  temp_df.to_csv(results_file, mode='a', header=header, index=False)\n",
    "  \n",
    "  print(f\"Results saved\")\n",
    "  \n",
    "  \n",
    "  os.makedirs(model_dir, exist_ok=True)\n",
    "  model_filename = f\"naive_bayes_{category.lower()}.joblib\"\n",
    "  model_path = os.path.join(model_dir, model_filename)\n",
    "  joblib.dump(best_model, model_path)\n",
    "  print(f\"Model for {category} saved to {model_path}\")\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b01846",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df = pd.read_csv(results_file)\n",
    "print(final_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
